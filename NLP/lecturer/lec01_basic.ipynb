{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0996d796-9ffd-4d7a-9bab-3004f98b7bb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KoNLPy 패키지 테스트\n",
    "* 한나눔(Hannanum), 꼬꼬마(Kkma), 코모란(Komoran),Okt(Open Korea Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d4db7-8b93-4d50-8aba-b7e9b6701821",
   "metadata": {},
   "source": [
    "## Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9bad338-91b6-4ad9-8f9a-6d120bddf655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['게시', '글', '공감']\n",
      "[]\n",
      "['아버지', '가', '방', '에', '들어가', '시', 'ㄴ다']\n",
      "[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('시', 'EP'), ('ㄴ다', 'EC')]\n",
      "[('아버지', 'NNG'), ('가방', 'NNP'), ('에', 'JKB'), ('들어가', 'VV'), ('시', 'EP'), ('ㄴ다', 'EC')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "print(komoran.nouns(\"게시글이 apple 좋았다면 Dr Hong 쿄쿄쿄 공감을 눌러주세요!!\"))\n",
    "\n",
    "print(komoran.nouns(\"This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.\"))\n",
    "\n",
    "print(komoran.morphs(\"아버지가 방에 들어가신다\"))\n",
    "print(komoran.pos('아버지가 방에 들어가신다'))\n",
    "\n",
    "print(komoran.pos('아버지가방에들어가신다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b992ff-52bd-4cc8-bcd8-8cc11225714f",
   "metadata": {},
   "source": [
    "## Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40984970-5b30-4633-aac7-69ed130f4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['게시', '글', '공감']\n",
      "[('아버지', 'Noun'), ('가', 'Josa'), ('방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb')]\n",
      "[('아버지', 'Noun'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "print(okt.nouns(\"게시글이 좋았다면 공감을 눌러주세요!!\"))\n",
    "\n",
    "print(okt.pos('아버지가 방에 들어가신다'))\n",
    "print(okt.pos('아버지가방에들어가신다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c510b58-4ac7-4a7b-927b-b3ccee389ecc",
   "metadata": {},
   "source": [
    "## Kkoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5558e913-a285-466d-b6f4-2aa2b6d3d718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['게시', '게시글', '글', '공감', '주세']\n",
      "[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKM'), ('들어가', 'VV'), ('시', 'EPH'), ('ㄴ다', 'EFN')]\n",
      "[('아버지', 'NNG'), ('가방', 'NNG'), ('에', 'JKM'), ('들어가', 'VV'), ('시', 'EPH'), ('ㄴ다', 'EFN')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "print(kkma.nouns(\"게시글이 좋았다면 공감을 눌러주세요!!\"))\n",
    "\n",
    "print(kkma.pos('아버지가 방에 들어가신다'))\n",
    "print(kkma.pos('아버지가방에들어가신다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abbdc6c-1bea-4148-9279-10d812238548",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16da7dc-47b9-4785-bcfa-9fc6dec04867",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 단어 토큰화(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06d4bfa-74a0-4d3a-a4e1-dfd8a5676903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re[a-zA-Z].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f5c505-8246-4645-a9ab-4c56fb35cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924e4791-be17-4f8e-82c0-e6bae6307b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f859750-1cdb-4caf-829d-2be64c2154f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " keras : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "print(' keras :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593c31e8-8d9e-41ed-b990-f7d154f8a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " keras : ['나는', '밥을', '먹는다']\n"
     ]
    }
   ],
   "source": [
    "print(' keras :',text_to_word_sequence(\"나는 밥을 먹는다.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46f447-f702-4151-a8cf-aa0a82d54a6f",
   "metadata": {},
   "source": [
    "## 문장 토큰화(Sentence Tokenization)\n",
    "* 구두점(.)으로 자른다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2200829b-a60e-4ae5-9bab-94656381a57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Since I'm actively looking.\",\n",
       " 'for Ph.D. Mr. students.',\n",
       " 'I get the same question a dozen times every year.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"Since I'm actively looking. for Ph.D. Mr. students. I get the same question a dozen times every year.\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5006aef6-3ad1-454c-885b-4be755016bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IP 192.168.56.31 서버에 들어가서 로그 파일 저장해서 aaa@gmail.com로 결과 좀.',\n",
       " '보내줘.',\n",
       " '그 후 점심 먹으러 가자.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"IP 192.168.56.31 서버에 들어가서 로그 파일 저장해서 aaa@gmail.com로 결과 좀. 보내줘. 그 후 점심 먹으러 가자.\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b712245-2c6a-44ce-9e60-24c95ce92e28",
   "metadata": {},
   "source": [
    "## 한국어 전용 띄어쓰기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d2d4fc-dda9-4068-8018-a2c2e19b8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135c8adf-5012-48a5-a44e-aac84ee40b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kss\n",
    "# text = '딥러닝 자연어처리가재미있기는 합니다. 이제 해보면 알걸요?'\n",
    "# print('한국어 문장 토큰화 :',kss.split_sentences(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7a0e8-f273-4e36-8d7e-675b56365d03",
   "metadata": {},
   "source": [
    "## 어간 & 표제어 추출\n",
    "<pre>\n",
    "Stemming\n",
    "am → am\n",
    "the going → the go\n",
    "having → hav\n",
    "\n",
    "Lemmatization\n",
    "am → be\n",
    "the going → the going\n",
    "having → have\n",
    "\n",
    "어간(stem) : 용언(동사, 형용사)을 활용할 때, 원칙적으로 모양이 변하지 않는 부분. 활용에서 어미에 선행하는 부분. 때론 어간의 모양도 바뀔 수 있음(예: 긋다, 긋고, 그어서, 그어라).\n",
    "\n",
    "어미(ending): 용언의 어간 뒤에 붙어서 활용하면서 변하는 부분이며, 여러 문법적 기능을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972a711-0522-4b50-b03d-ddab112e26a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 불용어(Stopword)\n",
    "* 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들\n",
    "* ./dataset/ko_stopword_dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42accbd-188c-4bd7-808e-183e882915a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "불용어 10개 출력 : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stop_words_list = stopwords.words('english')  #--------nltk\n",
    "print('불용어 개수 :', len(stop_words_list))\n",
    "print('불용어 10개 출력 :',stop_words_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6475d30-84d3-4166-ad19-1c04024d1683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['아', '휴', '아이구', '아이쿠', '아이고'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"./dataset/ko_stopword_dict.txt\")\n",
    "df['stop'].values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f31ff-4c4a-4361-a063-3bb7e2a33cd6",
   "metadata": {},
   "source": [
    "# mecab (은전한닢)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b581860d-53b1-458f-862a-b778be2b8975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('신다', 'EP+EC')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(r\"C:\\\\mecab\\\\mecab-ko-dic\")\n",
    "res = mecab.pos('아버지가방에들어가신다')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "730c58a4-713c-4a49-b0bf-93225f705f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!! \n",
      " 이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!\n",
      "품사 태깅: ['새롭', '개봉', '영화', '배우', '훌륭', '연기력', '아름다운', '목소리']\n",
      "단어토근화: ['이번', '개봉', '영화', '배우', '연기력', '목소리']\n",
      "이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!! \n",
      " !\n",
      "품사 태깅: []\n",
      "단어토근화: []\n",
      "--------------------------------------------------------------------------------\n",
      "나는 그 전처리를 아주 많이 베우고 있다. 그래서 나는 기분이 좋다 \n",
      " 나는 그 전처리를 아주 많이 베우고 있다.\n",
      "품사 태깅: ['는', '전처리', '아주', '많이', '베', '우', '다']\n",
      "단어토근화: ['나', '전처리']\n",
      "나는 그 전처리를 아주 많이 베우고 있다. 그래서 나는 기분이 좋다 \n",
      " 그래서 나는 기분이 좋다\n",
      "품사 태깅: ['는', '기분', '좋', '다']\n",
      "단어토근화: ['나', '기분']\n",
      "--------------------------------------------------------------------------------\n",
      "어제의 최상현은 정말 잘생겼다고 생각하지 않는다. \n",
      " 어제의 최상현은 정말 잘생겼다고 생각하지 않는다.\n",
      "품사 태깅: ['어제', '최상현', '정말', '잘', '생겼', '다고', '생각', '지', '않', '는다']\n",
      "단어토근화: ['어제', '최상현', '생각']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# from konlpy.tag import Okt\n",
    "from konlpy.tag import Mecab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def my_stopword(text,tokenizer):    \n",
    "    #stopwords = ['이번','에','을', '를', '이', '가', '은', '는']\n",
    "    df = pd.read_csv(\"./dataset/ko_stopword_dict.txt\") #------ 기본 header=None\n",
    "    list1 = df['stop'].values.tolist()\n",
    "    \n",
    "    list2 = ['게','한','은', '갖', '고', '있']                           #------ 추가본\n",
    "    stopwords = list1 + list2\n",
    "    \n",
    "    txt = re.sub('[^가-힣a-z]', ' ', text)\n",
    "    # token = tokenizer.morphs(txt)\n",
    "    mecab_morphs = mecab.morphs(txt)\n",
    "    token = [t for t in mecab_morphs if t not in stopwords]\n",
    "    return token\n",
    "\n",
    "# tokenizer = Okt()\n",
    "mecab = Mecab(r\"C:\\\\mecab\\\\mecab-ko-dic\")\n",
    "\n",
    "\n",
    "text_list = [\"이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!!\",\n",
    "             \"나는 그 전처리를 아주 많이 베우고 있다. 그래서 나는 기분이 좋다\",\n",
    "             \"어제의 최상현은 정말 잘생겼다고 생각하지 않는다.\"]\n",
    "print( len(text_list))\n",
    "\n",
    "for text in text_list:\n",
    "    for sent in sent_tokenize(text):\n",
    "        res= my_stopword(sent,mecab)\n",
    "        print(text, '\\n', sent)\n",
    "        print(\"품사 태깅:\", res)\n",
    "        print(\"단어토근화:\",mecab.nouns(sent))\n",
    "    print(\"----\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a70f34-83a6-49db-b758-2dfefc8d353d",
   "metadata": {},
   "source": [
    "# [실습] 식수예측(중식메뉴) \n",
    "* 중식메뉴 + (워드클라우드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e3a2d-c808-410c-88a3-f8af7682e8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5e23f-4d49-4c6b-97a5-48f56d7882f7",
   "metadata": {},
   "outputs": [],
   "source": [
    " & 정제(cleaning) & 정규화(normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a2451-fad5-4306-b5de-5281ebe7bf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf016944-6915-4010-b403-7a607a486bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1dc6d-d5be-4fc4-a504-1de0b137ac55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
